{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Study\\\\RMIT\\\\2022\\\\COSC2793 - Computational Machine Learning\\\\Assignment02\\\\CML-Assign2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('D:\\\\Study\\\\RMIT\\\\2022\\\\COSC2793 - Computational Machine Learning\\\\Assignment02\\\\CML-Assign2')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.simplest_intersection import SimplestIntersection\n",
    "from final_simulation._sumo.simplest_intersection_simulation import SignalStates, SumoSimulation\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulation(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = SimplestIntersection(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_08\\\\ppo\\\\trained_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_07\\\\a2c\\\\trained_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersection9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulation(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersection9(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_10\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_10\\\\a2c\\\\best_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No simulation running.\n",
      "saving observation file..\n",
      "info: {'traffic':                 approaching_cars  stopped_cars  average_speed  \\\n",
      "routes                                                          \n",
      "east_to_north                0.0           0.0       0.000000   \n",
      "east_to_south                0.0           0.0       0.000000   \n",
      "east_to_west                 1.0           1.0       0.000000   \n",
      "north_to_east                0.0           0.0       0.000000   \n",
      "north_to_south               4.0           1.0       8.577890   \n",
      "north_to_west                1.0           0.0       9.423480   \n",
      "south_to_east                0.0           0.0       0.000000   \n",
      "south_to_north              13.0           1.0       2.744039   \n",
      "south_to_west                1.0           0.0       9.043985   \n",
      "west_to_east                 1.0           1.0       0.000000   \n",
      "west_to_north                7.0           6.0       2.503527   \n",
      "west_to_south                4.0           3.0       2.861599   \n",
      "\n",
      "                accumulated_waiting_time  new_throughput  \n",
      "routes                                                    \n",
      "east_to_north                        0.0             0.0  \n",
      "east_to_south                        0.0             0.0  \n",
      "east_to_west                         3.0             0.0  \n",
      "north_to_east                        0.0             0.0  \n",
      "north_to_south                       3.0             0.0  \n",
      "north_to_west                        0.0             0.0  \n",
      "south_to_east                        0.0             0.0  \n",
      "south_to_north                       6.0             0.0  \n",
      "south_to_west                        0.0             0.0  \n",
      "west_to_east                        43.0             0.0  \n",
      "west_to_north                      106.0             0.0  \n",
      "west_to_south                      135.0             0.0  , 'signal_state': 0, 'previous_signal_state': 0, 'previous_signal_active_time': 3, 'simulation_time': 180.0, 'reward': -13.0}\n",
      "\n",
      "            Total Time Steps: 180\n",
      "            Previous Signal: rgrrrgrr\n",
      "            Total Signal Changes: 79\n",
      "            Total Throughput: 82.0\n",
      "            Total Wait Time: 27851.0\n",
      "            Total Reward: -1457.0\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersection11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulation(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersection11(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_11\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_10\\\\a2c\\\\best_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No simulation running.\n",
      "saving observation file..\n",
      "info: {'traffic':                 approaching_cars  stopped_cars  average_speed  \\\n",
      "routes                                                          \n",
      "east_to_north                0.0           0.0       0.000000   \n",
      "east_to_south                0.0           0.0       0.000000   \n",
      "east_to_west                 1.0           1.0       0.000000   \n",
      "north_to_east                0.0           0.0       0.000000   \n",
      "north_to_south               3.0           0.0       9.267559   \n",
      "north_to_west                1.0           0.0      10.001836   \n",
      "south_to_east                0.0           0.0       0.000000   \n",
      "south_to_north               5.0           2.0       6.925669   \n",
      "south_to_west                1.0           0.0      10.379301   \n",
      "west_to_east                 0.0           0.0       0.000000   \n",
      "west_to_north                1.0           0.0      12.789200   \n",
      "west_to_south                1.0           0.0      12.015986   \n",
      "\n",
      "                accumulated_waiting_time  new_throughput  \n",
      "routes                                                    \n",
      "east_to_north                        0.0             0.0  \n",
      "east_to_south                        0.0             0.0  \n",
      "east_to_west                         4.0             0.0  \n",
      "north_to_east                        0.0             0.0  \n",
      "north_to_south                       0.0             0.0  \n",
      "north_to_west                        0.0             0.0  \n",
      "south_to_east                        0.0             0.0  \n",
      "south_to_north                       6.0             0.0  \n",
      "south_to_west                        0.0             0.0  \n",
      "west_to_east                         0.0             0.0  \n",
      "west_to_north                        0.0             0.0  \n",
      "west_to_south                        0.0             0.0  , 'signal_state': 0, 'previous_signal_state': 2, 'previous_signal_active_time': 5, 'simulation_time': 180.0, 'reward': -13.0}\n",
      "\n",
      "            Total Time Steps: 180\n",
      "            Previous Signal: rgrrrgrr\n",
      "            Total Signal Changes: 82\n",
      "            Total Throughput: 101.0\n",
      "            Total Wait Time: 3196.0\n",
      "            Total Reward: -5514.0\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 12 (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersectionSimpleObs12\n",
    "from final_simulation._sumo.simplest_intersection_simulation import SumoSimulationSimpleObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulationSimpleObs(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersectionSimpleObs12(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_12\\\\simple\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_10\\\\a2c\\\\best_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No simulation running.\n",
      "saving observation file..\n",
      "info: {'traffic':        stopped_cars\n",
      "entry              \n",
      "east              3\n",
      "north             3\n",
      "south             2\n",
      "west             11, 'signal_state': 0, 'previous_signal_state': 0, 'previous_signal_active_time': 2, 'simulation_time': 180.0, 'reward': -19.0}\n",
      "\n",
      "            Total Time Steps: 180\n",
      "            Total Signal Changes: 53\n",
      "            Total Throughput: 68\n",
      "            Total Reward: -1253.0\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f344f29490a86472adfcb0d4c68c5dfdcf97bca003fdba9df268b07cb4a6c3e0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 ('_penv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
