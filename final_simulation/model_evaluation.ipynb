{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Study\\\\RMIT\\\\2022\\\\COSC2793 - Computational Machine Learning\\\\Assignment02\\\\CML-Assign2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('D:\\\\Study\\\\RMIT\\\\2022\\\\COSC2793 - Computational Machine Learning\\\\Assignment02\\\\CML-Assign2')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "from final_simulation._env.simplest_intersection import SimplestIntersection\n",
    "from final_simulation._sumo.simplest_intersection_simulation import SignalStates, SumoSimulation\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulation(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = SimplestIntersection(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_08\\\\ppo\\\\trained_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_07\\\\a2c\\\\trained_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersection9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulation(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersection9(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_10\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_10\\\\a2c\\\\best_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersection11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulation(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersection11(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_11\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_10\\\\a2c\\\\best_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 12 (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersectionSimpleObs12\n",
    "from final_simulation._sumo.simplest_intersection_simulation import SumoSimulationSimpleObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulationSimpleObs(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersectionSimpleObs12(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_12\\\\simple\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_10\\\\a2c\\\\best_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 13 (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersectionSimpleObs13\n",
    "from final_simulation._sumo.simplest_intersection_simulation import SumoSimulationSimpleObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulationSimpleObs(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersectionSimpleObs13(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = PPO.load(\"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\a2c\\\\best_model.zip\")\n",
    "model = DQN.load(\"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\dqn\\\\best_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No simulation running.\n",
      "saving observation file..\n",
      "info: {'traffic':        stopped_cars\n",
      "entry              \n",
      "east              1\n",
      "north             4\n",
      "south             1\n",
      "west             15, 'signal_state': 2, 'previous_signal_state': 2, 'previous_signal_active_time': 6, 'simulation_time': 180.0, 'reward': -21.0}\n",
      "\n",
      "            Total Time Steps: 180\n",
      "            Total Signal Changes: 29\n",
      "            Total Throughput: 83\n",
      "            Total Reward: -1775.0\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f344f29490a86472adfcb0d4c68c5dfdcf97bca003fdba9df268b07cb4a6c3e0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 ('_penv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
