{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Study\\\\RMIT\\\\2022\\\\COSC2793 - Computational Machine Learning\\\\Assignment02\\\\CML-Assign2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('D:\\\\Study\\\\RMIT\\\\2022\\\\COSC2793 - Computational Machine Learning\\\\Assignment02\\\\CML-Assign2')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersectionSimpleObs13, RealIntersectionSimpleObs13_Static\n",
    "from final_simulation._sumo.simplest_intersection_simulation import SignalStates, SumoSimulationSimpleObs\n",
    "from final_simulation.sarsa import SARSA_Eval\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Models Eval\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "n_episodes = 3\n",
    "max_simulation_seconds = 300\n",
    "\n",
    "simulation = SumoSimulationSimpleObs(\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersectionSimpleObs13(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")\n",
    "\n",
    "env_static = RealIntersectionSimpleObs13_Static(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\ppo\\\\best_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(1,n_episodes + 1):\n",
    "\n",
    "    print(\"Episode: \", episode)\n",
    "\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while done != True:\n",
    "        \n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "        if done:\n",
    "            env.save_metrics(\n",
    "                episode=episode,\n",
    "                model_name=\"PPO\",\n",
    "                log_dir=\"final_simulation\\\\_models\\\\eval\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(\"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\dqn\\\\best_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(1,n_episodes + 1):\n",
    "\n",
    "    print(\"Episode: \", episode)\n",
    "\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while done != True:\n",
    "        \n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "        if done:\n",
    "            env.save_metrics(\n",
    "                episode=episode,\n",
    "                model_name=\"DQN\",\n",
    "                log_dir=\"final_simulation\\\\_models\\\\eval\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C.load(\"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\a2c\\\\best_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(1,n_episodes + 1):\n",
    "\n",
    "    print(\"Episode: \", episode)\n",
    "\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while done != True:\n",
    "        \n",
    "        action, _states = model.predict(observation)\n",
    "        observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "        if done:\n",
    "            env.save_metrics(\n",
    "                episode=episode,\n",
    "                model_name=\"A2C\",\n",
    "                log_dir=\"final_simulation\\\\_models\\\\eval\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARSA_Eval(\n",
    "    q_table_path=\"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\sarsa\\\\final_q_table.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "Episode:  2\n",
      "No simulation running.\n"
     ]
    }
   ],
   "source": [
    "for episode in range(1,n_episodes + 1):\n",
    "\n",
    "    print(\"Episode: \", episode)\n",
    "\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while done != True:\n",
    "        \n",
    "        action = model.predict(observation)\n",
    "        observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "        if done:\n",
    "            env.save_metrics(\n",
    "                episode=episode,\n",
    "                model_name=\"SARSA\",\n",
    "                log_dir=\"final_simulation\\\\_models\\\\eval\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(1,n_episodes + 1):\n",
    "\n",
    "    print(\"Episode: \", episode)\n",
    "\n",
    "    observation = env_static.reset()\n",
    "    done = False\n",
    "\n",
    "    while done != True:\n",
    "\n",
    "        observation, reward, done, info = env_static.step(0)\n",
    "\n",
    "        if done:\n",
    "            env_static.save_metrics(\n",
    "                episode=episode,\n",
    "                model_name=\"STATIC\",\n",
    "                log_dir=\"final_simulation\\\\_models\\\\eval\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulation(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = SimplestIntersection(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_08\\\\ppo\\\\trained_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_07\\\\a2c\\\\trained_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersection9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulation(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersection9(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_10\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_10\\\\a2c\\\\best_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersection11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulation(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersection11(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_11\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_10\\\\a2c\\\\best_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 12 (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersectionSimpleObs12\n",
    "from final_simulation._sumo.simplest_intersection_simulation import SumoSimulationSimpleObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulationSimpleObs(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersectionSimpleObs12(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"final_simulation\\\\_models\\\\reward_12\\\\simple\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_10\\\\a2c\\\\best_model.zip\")\n",
    "#model = DQN.load(\"final_simulation\\\\_models\\\\reward_07\\\\dqn\\\\trained_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 13 (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersectionSimpleObs13\n",
    "from final_simulation._sumo.simplest_intersection_simulation import SumoSimulationSimpleObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "\n",
    "simulation = SumoSimulationSimpleObs(\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "env = RealIntersectionSimpleObs13(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = PPO.load(\"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\ppo\\\\best_model.zip\")\n",
    "#model = A2C.load(\"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\a2c\\\\best_model.zip\")\n",
    "model = DQN.load(\"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\dqn\\\\best_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    #observation = observation[np.newaxis, ...]\n",
    "\n",
    "    # action = env.action_space.sample()\n",
    "    action, _states = model.predict(observation)\n",
    "    observation, reward, done, info = env.step(float(action))\n",
    "\n",
    "    # env.render()\n",
    "    if done:\n",
    "        print(\"info:\", info)\n",
    "        env.render()\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f344f29490a86472adfcb0d4c68c5dfdcf97bca003fdba9df268b07cb4a6c3e0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 ('_penv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
