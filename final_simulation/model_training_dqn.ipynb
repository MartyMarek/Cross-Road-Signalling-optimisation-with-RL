{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Study\\\\RMIT\\\\2022\\\\COSC2793 - Computational Machine Learning\\\\Assignment02\\\\CML-Assign2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('D:\\\\Study\\\\RMIT\\\\2022\\\\COSC2793 - Computational Machine Learning\\\\Assignment02\\\\CML-Assign2')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_simulation._env.real_intersection import RealIntersection8, RealIntersection10, RealIntersection11, RealIntersectionSimpleObs12, RealIntersectionSimpleObs13\n",
    "from final_simulation._sumo.simplest_intersection_simulation import SignalStates, SumoSimulation, SumoSimulationSimpleObs\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from final_simulation._env.callbacks import SaveOnBestTrainingRewardCallback\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"final_simulation\\\\_models\\\\reward_08\\\\dqn\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 90\n",
    "number_episodes = 500\n",
    "\n",
    "# Save best check frequency\n",
    "check_freq = max_simulation_seconds * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation\n",
    "simulation = SumoSimulation(\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "# Define environment\n",
    "env = RealIntersection8(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")\n",
    "\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "# Callback\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=check_freq,log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent\n",
    "model = DQN('MultiInputPolicy', env, device='auto',learning_rate=0.01, exploration_initial_eps=1, exploration_final_eps=0.01, verbose=1)\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(max_simulation_seconds*number_episodes),callback=callback)\n",
    "model.save(\"{0}\\\\final_model\".format(log_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"final_simulation\\\\_models\\\\reward_10\\\\dqn\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 90\n",
    "number_episodes = 1000\n",
    "\n",
    "# Save best check frequency\n",
    "check_freq = max_simulation_seconds * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation\n",
    "simulation = SumoSimulation(\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "# Define environment\n",
    "env = RealIntersection10(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")\n",
    "\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "# Callback\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=check_freq,log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent\n",
    "model = DQN('MultiInputPolicy', env, device='auto',learning_rate=0.001, exploration_initial_eps=1, exploration_final_eps=0.01, verbose=1)\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(max_simulation_seconds*number_episodes),callback=callback)\n",
    "model.save(\"{0}\\\\final_model\".format(log_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"final_simulation\\\\_models\\\\reward_11\\\\dqn\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "number_episodes = 500\n",
    "\n",
    "# Save best check frequency\n",
    "check_freq = max_simulation_seconds * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation\n",
    "simulation = SumoSimulation(\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "# Define environment\n",
    "env = RealIntersection11(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")\n",
    "\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "# Callback\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=check_freq,log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent\n",
    "model = DQN('MultiInputPolicy', env, device='auto',learning_rate=0.001, exploration_initial_eps=1, exploration_final_eps=0.01, verbose=1)\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(max_simulation_seconds*number_episodes),callback=callback)\n",
    "model.save(\"{0}\\\\final_model\".format(log_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 12 (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"final_simulation\\\\_models\\\\reward_12\\\\simple\\\\dqn\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "number_episodes = 500\n",
    "\n",
    "# Save best check frequency\n",
    "check_freq = max_simulation_seconds * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation\n",
    "simulation = SumoSimulationSimpleObs(\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "# Define environment\n",
    "env = RealIntersectionSimpleObs12(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")\n",
    "\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "# Callback\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=check_freq,log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent\n",
    "model = DQN('MlpPolicy', env, device='auto',learning_rate=0.001, exploration_initial_eps=1, exploration_final_eps=0.01, verbose=1)\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(max_simulation_seconds*number_episodes),callback=callback)\n",
    "model.save(\"{0}\\\\final_model\".format(log_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 13 (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"final_simulation\\\\_models\\\\reward_13\\\\simple\\\\dqn\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 180\n",
    "number_episodes = 1000\n",
    "\n",
    "# Save best check frequency\n",
    "check_freq = max_simulation_seconds * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation\n",
    "simulation = SumoSimulationSimpleObs(\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "# Define environment\n",
    "env = RealIntersectionSimpleObs13(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")\n",
    "\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "# Callback\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=check_freq,log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent\n",
    "model = DQN('MlpPolicy', env, device='auto',learning_rate=0.001, exploration_initial_eps=1, exploration_final_eps=0.01, verbose=1)\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(max_simulation_seconds*number_episodes),callback=callback)\n",
    "model.save(\"{0}\\\\final_model\".format(log_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Training\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR 0.1, decay 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"final_simulation\\\\_models\\\\final\\\\dqn\\\\lr_0_1_ed_0_001\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Sim time 1 minute\n",
    "max_simulation_seconds = 120\n",
    "number_episodes = 2000\n",
    "\n",
    "# Save best check frequency\n",
    "check_freq = max_simulation_seconds * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation\n",
    "simulation = SumoSimulationSimpleObs(\n",
    "    sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo\",\n",
    "    #sumo_binary_path=\"C:\\\\Program Files (x86)\\\\Eclipse\\\\Sumo\\\\bin\\\\sumo-gui\",\n",
    "    sumo_config_path=\"C:\\\\sumoconfig\\\\real_intersection.sumocfg\",\n",
    "    signal_states=SignalStates\n",
    ")\n",
    "\n",
    "# Define environment\n",
    "env = RealIntersectionSimpleObs13(\n",
    "    simulation=simulation,\n",
    "    max_simulation_seconds=max_simulation_seconds\n",
    ")\n",
    "\n",
    "# Logs will be saved in log_dir/monitor.csv\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "# Callback\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=check_freq,log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.92e+03 |\n",
      "|    exploration_rate | 0.996     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 78        |\n",
      "|    total_timesteps  | 476       |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.65e+03 |\n",
      "|    exploration_rate | 0.993     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 157       |\n",
      "|    total_timesteps  | 952       |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 1200\n",
      "Best mean reward: -inf - Last mean reward per episode: -3672.50\n",
      "Saving new best model to final_simulation\\_models\\final\\dqn\\lr_0_1_ed_0_001\\best_model\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.61e+03 |\n",
      "|    exploration_rate | 0.989     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 5         |\n",
      "|    time_elapsed     | 239       |\n",
      "|    total_timesteps  | 1428      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.986     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 5         |\n",
      "|    time_elapsed     | 318       |\n",
      "|    total_timesteps  | 1904      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.59e+03 |\n",
      "|    exploration_rate | 0.982     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 395       |\n",
      "|    total_timesteps  | 2380      |\n",
      "-----------------------------------\n",
      "Num timesteps: 2400\n",
      "Best mean reward: -3672.50 - Last mean reward per episode: -3586.85\n",
      "Saving new best model to final_simulation\\_models\\final\\dqn\\lr_0_1_ed_0_001\\best_model\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.59e+03 |\n",
      "|    exploration_rate | 0.979     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 474       |\n",
      "|    total_timesteps  | 2856      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.55e+03 |\n",
      "|    exploration_rate | 0.975     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 550       |\n",
      "|    total_timesteps  | 3332      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 3600\n",
      "Best mean reward: -3586.85 - Last mean reward per episode: -3562.57\n",
      "Saving new best model to final_simulation\\_models\\final\\dqn\\lr_0_1_ed_0_001\\best_model\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.55e+03 |\n",
      "|    exploration_rate | 0.971     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 630       |\n",
      "|    total_timesteps  | 3808      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.56e+03 |\n",
      "|    exploration_rate | 0.968     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 709       |\n",
      "|    total_timesteps  | 4284      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.964     |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 791       |\n",
      "|    total_timesteps  | 4760      |\n",
      "-----------------------------------\n",
      "Num timesteps: 4800\n",
      "Best mean reward: -3562.57 - Last mean reward per episode: -3578.97\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.961     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 5         |\n",
      "|    time_elapsed     | 872       |\n",
      "|    total_timesteps  | 5236      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.957     |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 5         |\n",
      "|    time_elapsed     | 952       |\n",
      "|    total_timesteps  | 5712      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 6000\n",
      "Best mean reward: -3562.57 - Last mean reward per episode: -3559.82\n",
      "Saving new best model to final_simulation\\_models\\final\\dqn\\lr_0_1_ed_0_001\\best_model\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.954     |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 5         |\n",
      "|    time_elapsed     | 1031      |\n",
      "|    total_timesteps  | 6188      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.56e+03 |\n",
      "|    exploration_rate | 0.95      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 5         |\n",
      "|    time_elapsed     | 1114      |\n",
      "|    total_timesteps  | 6664      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.56e+03 |\n",
      "|    exploration_rate | 0.946     |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 1187      |\n",
      "|    total_timesteps  | 7140      |\n",
      "-----------------------------------\n",
      "Num timesteps: 7200\n",
      "Best mean reward: -3559.82 - Last mean reward per episode: -3559.75\n",
      "Saving new best model to final_simulation\\_models\\final\\dqn\\lr_0_1_ed_0_001\\best_model\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.943     |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 1265      |\n",
      "|    total_timesteps  | 7616      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.939     |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 5         |\n",
      "|    time_elapsed     | 1349      |\n",
      "|    total_timesteps  | 8092      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 8400\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3567.83\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.936     |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 1427      |\n",
      "|    total_timesteps  | 8568      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.932     |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 5         |\n",
      "|    time_elapsed     | 1507      |\n",
      "|    total_timesteps  | 9044      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.929     |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 5         |\n",
      "|    time_elapsed     | 1587      |\n",
      "|    total_timesteps  | 9520      |\n",
      "-----------------------------------\n",
      "Num timesteps: 9600\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3576.97\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.925     |\n",
      "| time/               |           |\n",
      "|    episodes         | 84        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 1663      |\n",
      "|    total_timesteps  | 9996      |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.921     |\n",
      "| time/               |           |\n",
      "|    episodes         | 88        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 1740      |\n",
      "|    total_timesteps  | 10472     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 10800\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3577.07\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.918     |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 1817      |\n",
      "|    total_timesteps  | 10948     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.914     |\n",
      "| time/               |           |\n",
      "|    episodes         | 96        |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 1899      |\n",
      "|    total_timesteps  | 11424     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.911     |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 1977      |\n",
      "|    total_timesteps  | 11900     |\n",
      "-----------------------------------\n",
      "Num timesteps: 12000\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3576.29\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.56e+03 |\n",
      "|    exploration_rate | 0.907     |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2057      |\n",
      "|    total_timesteps  | 12376     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.904     |\n",
      "| time/               |           |\n",
      "|    episodes         | 108       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2134      |\n",
      "|    total_timesteps  | 12852     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 13200\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3568.96\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.9       |\n",
      "| time/               |           |\n",
      "|    episodes         | 112       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2216      |\n",
      "|    total_timesteps  | 13328     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.896     |\n",
      "| time/               |           |\n",
      "|    episodes         | 116       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2296      |\n",
      "|    total_timesteps  | 13804     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.893     |\n",
      "| time/               |           |\n",
      "|    episodes         | 120       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2374      |\n",
      "|    total_timesteps  | 14280     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 14400\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3582.37\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.889     |\n",
      "| time/               |           |\n",
      "|    episodes         | 124       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2452      |\n",
      "|    total_timesteps  | 14756     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.59e+03 |\n",
      "|    exploration_rate | 0.886     |\n",
      "| time/               |           |\n",
      "|    episodes         | 128       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2529      |\n",
      "|    total_timesteps  | 15232     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 15600\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3585.86\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | -3.6e+03 |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 6        |\n",
      "|    time_elapsed     | 2608     |\n",
      "|    total_timesteps  | 15708    |\n",
      "----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.59e+03 |\n",
      "|    exploration_rate | 0.879     |\n",
      "| time/               |           |\n",
      "|    episodes         | 136       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2686      |\n",
      "|    total_timesteps  | 16184     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.875     |\n",
      "| time/               |           |\n",
      "|    episodes         | 140       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2763      |\n",
      "|    total_timesteps  | 16660     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 16800\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3574.92\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.871     |\n",
      "| time/               |           |\n",
      "|    episodes         | 144       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2844      |\n",
      "|    total_timesteps  | 17136     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.59e+03 |\n",
      "|    exploration_rate | 0.868     |\n",
      "| time/               |           |\n",
      "|    episodes         | 148       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 2924      |\n",
      "|    total_timesteps  | 17612     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 18000\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3586.55\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.864     |\n",
      "| time/               |           |\n",
      "|    episodes         | 152       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3000      |\n",
      "|    total_timesteps  | 18088     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.59e+03 |\n",
      "|    exploration_rate | 0.861     |\n",
      "| time/               |           |\n",
      "|    episodes         | 156       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3078      |\n",
      "|    total_timesteps  | 18564     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.857     |\n",
      "| time/               |           |\n",
      "|    episodes         | 160       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3154      |\n",
      "|    total_timesteps  | 19040     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 19200\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3576.13\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.56e+03 |\n",
      "|    exploration_rate | 0.854     |\n",
      "| time/               |           |\n",
      "|    episodes         | 164       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3227      |\n",
      "|    total_timesteps  | 19516     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.56e+03 |\n",
      "|    exploration_rate | 0.85      |\n",
      "| time/               |           |\n",
      "|    episodes         | 168       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3305      |\n",
      "|    total_timesteps  | 19992     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 20400\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3563.03\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.846     |\n",
      "| time/               |           |\n",
      "|    episodes         | 172       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3382      |\n",
      "|    total_timesteps  | 20468     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.843     |\n",
      "| time/               |           |\n",
      "|    episodes         | 176       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3462      |\n",
      "|    total_timesteps  | 20944     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.839     |\n",
      "| time/               |           |\n",
      "|    episodes         | 180       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3541      |\n",
      "|    total_timesteps  | 21420     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 21600\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3574.58\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.836     |\n",
      "| time/               |           |\n",
      "|    episodes         | 184       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3622      |\n",
      "|    total_timesteps  | 21896     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.832     |\n",
      "| time/               |           |\n",
      "|    episodes         | 188       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3699      |\n",
      "|    total_timesteps  | 22372     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 22800\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3576.82\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.829     |\n",
      "| time/               |           |\n",
      "|    episodes         | 192       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3776      |\n",
      "|    total_timesteps  | 22848     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.825     |\n",
      "| time/               |           |\n",
      "|    episodes         | 196       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3854      |\n",
      "|    total_timesteps  | 23324     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.822     |\n",
      "| time/               |           |\n",
      "|    episodes         | 200       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 3932      |\n",
      "|    total_timesteps  | 23800     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 24000\n",
      "Best mean reward: -3559.75 - Last mean reward per episode: -3559.71\n",
      "Saving new best model to final_simulation\\_models\\final\\dqn\\lr_0_1_ed_0_001\\best_model\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.56e+03 |\n",
      "|    exploration_rate | 0.818     |\n",
      "| time/               |           |\n",
      "|    episodes         | 204       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4011      |\n",
      "|    total_timesteps  | 24276     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.56e+03 |\n",
      "|    exploration_rate | 0.814     |\n",
      "| time/               |           |\n",
      "|    episodes         | 208       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4087      |\n",
      "|    total_timesteps  | 24752     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 25200\n",
      "Best mean reward: -3559.71 - Last mean reward per episode: -3569.40\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.811     |\n",
      "| time/               |           |\n",
      "|    episodes         | 212       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4168      |\n",
      "|    total_timesteps  | 25228     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.807     |\n",
      "| time/               |           |\n",
      "|    episodes         | 216       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4247      |\n",
      "|    total_timesteps  | 25704     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.804     |\n",
      "| time/               |           |\n",
      "|    episodes         | 220       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4326      |\n",
      "|    total_timesteps  | 26180     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 26400\n",
      "Best mean reward: -3559.71 - Last mean reward per episode: -3575.80\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.8       |\n",
      "| time/               |           |\n",
      "|    episodes         | 224       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4407      |\n",
      "|    total_timesteps  | 26656     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.797     |\n",
      "| time/               |           |\n",
      "|    episodes         | 228       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4484      |\n",
      "|    total_timesteps  | 27132     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 27600\n",
      "Best mean reward: -3559.71 - Last mean reward per episode: -3568.96\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.793     |\n",
      "| time/               |           |\n",
      "|    episodes         | 232       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4561      |\n",
      "|    total_timesteps  | 27608     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.789     |\n",
      "| time/               |           |\n",
      "|    episodes         | 236       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4639      |\n",
      "|    total_timesteps  | 28084     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.786     |\n",
      "| time/               |           |\n",
      "|    episodes         | 240       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4716      |\n",
      "|    total_timesteps  | 28560     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 28800\n",
      "Best mean reward: -3559.71 - Last mean reward per episode: -3560.69\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.56e+03 |\n",
      "|    exploration_rate | 0.782     |\n",
      "| time/               |           |\n",
      "|    episodes         | 244       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4794      |\n",
      "|    total_timesteps  | 29036     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.57e+03 |\n",
      "|    exploration_rate | 0.779     |\n",
      "| time/               |           |\n",
      "|    episodes         | 248       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4877      |\n",
      "|    total_timesteps  | 29512     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.58e+03 |\n",
      "|    exploration_rate | 0.775     |\n",
      "| time/               |           |\n",
      "|    episodes         | 252       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 4958      |\n",
      "|    total_timesteps  | 29988     |\n",
      "-----------------------------------\n",
      "Num timesteps: 30000\n",
      "Best mean reward: -3559.71 - Last mean reward per episode: -3583.62\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.59e+03 |\n",
      "|    exploration_rate | 0.772     |\n",
      "| time/               |           |\n",
      "|    episodes         | 256       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 5040      |\n",
      "|    total_timesteps  | 30464     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.61e+03 |\n",
      "|    exploration_rate | 0.768     |\n",
      "| time/               |           |\n",
      "|    episodes         | 260       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 5117      |\n",
      "|    total_timesteps  | 30940     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "Num timesteps: 31200\n",
      "Best mean reward: -3559.71 - Last mean reward per episode: -3615.89\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.63e+03 |\n",
      "|    exploration_rate | 0.764     |\n",
      "| time/               |           |\n",
      "|    episodes         | 264       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 5198      |\n",
      "|    total_timesteps  | 31416     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.63e+03 |\n",
      "|    exploration_rate | 0.761     |\n",
      "| time/               |           |\n",
      "|    episodes         | 268       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 5276      |\n",
      "|    total_timesteps  | 31892     |\n",
      "-----------------------------------\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 119       |\n",
      "|    ep_rew_mean      | -3.62e+03 |\n",
      "|    exploration_rate | 0.757     |\n",
      "| time/               |           |\n",
      "|    episodes         | 272       |\n",
      "|    fps              | 6         |\n",
      "|    time_elapsed     | 5356      |\n",
      "|    total_timesteps  | 32368     |\n",
      "-----------------------------------\n",
      "Num timesteps: 32400\n",
      "Best mean reward: -3559.71 - Last mean reward per episode: -3615.30\n",
      "saving observation file..\n",
      "No simulation running.\n",
      "saving observation file..\n",
      "No simulation running.\n"
     ]
    }
   ],
   "source": [
    "# Define agent\n",
    "model = DQN('MlpPolicy', env, device='auto',learning_rate=0.1, exploration_initial_eps=1, exploration_final_eps=0.1, exploration_fraction=0.5, gamma=0.9, verbose=1)\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(max_simulation_seconds*number_episodes),callback=callback)\n",
    "model.save(\"{0}\\\\final_model\".format(log_dir))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f344f29490a86472adfcb0d4c68c5dfdcf97bca003fdba9df268b07cb4a6c3e0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 ('_penv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
