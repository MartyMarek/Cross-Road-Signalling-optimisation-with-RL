{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from final_simulation._env.real_intersection import RealIntersection8, RealIntersection10, RealIntersection11\n",
    "from final_simulation._sumo.simplest_intersection_simulation import SignalStates, SumoSimulation\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numBins = 20\n",
    "bins = [np.linspace(-4.8, 4.8, numBins),\n",
    "        np.linspace(-4, 4, numBins),\n",
    "        np.linspace(-.418, .418, numBins),\n",
    "        np.linspace(-4, 4, numBins)]\n",
    "obsSpaceSize = len(env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_state(state, bins, obsSpaceSize):\n",
    "    stateIndex = []\n",
    "    for i in range(obsSpaceSize):\n",
    "        stateIndex.append(np.digitize(state[i], bins[i]) - 1) # -1 will turn bin into index\n",
    "    return tuple(stateIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT = 0.95\n",
    "EPISODES = 50000\n",
    "\n",
    "# parameters for epsilon decay policy\n",
    "EPSILON = 1 # not a constant, going to be decayed\n",
    "START_EPSILON_DECAYING = 1\n",
    "END_EPSILON_DECAYING = EPISODES // 2\n",
    "epsilon_decay_value = EPSILON / (END_EPSILON_DECAYING - START_EPSILON_DECAYING)\n",
    "\n",
    "#for testing\n",
    "N_TEST_RUNS = 100\n",
    "TEST_INTERVAL = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARSA(env, QTable):\n",
    "    # Env: The OpenAI gym environment\n",
    "    # QTable: Initial Q table\n",
    "    \n",
    "    for episode in range(EPISODES):\n",
    "        done = False\n",
    "        \n",
    "        # get the initial state\n",
    "        state = env.reset()\n",
    "        discretState = discretize_state(state, bins, obsSpaceSize)\n",
    "        \n",
    "        epsilon = EPSILON\n",
    "    \n",
    "        steps = 0;\n",
    "        while done != True:   \n",
    "                \n",
    "            # Determine next action - epsilon greedy strategy for explore vs exploitation\n",
    "            if np.random.random() < 1 - epsilon:\n",
    "                # select the best action according to Qtable (exploitation)\n",
    "                # TODO\n",
    "            else:\n",
    "                # select a random action (exploration)\n",
    "                # TODO\n",
    "                \n",
    "            # Step and Get the next state and reward\n",
    "            # TODO\n",
    "            \n",
    "            \n",
    "            #Allow for terminal states\n",
    "            if done and steps < 200:\n",
    "                reward = -375    # what is happending here?\n",
    "                \n",
    "            # Update the Q table\n",
    "            # TODO\n",
    "                                     \n",
    "            # Update variables\n",
    "            discretState = discretStateNew\n",
    "            steps = steps + 1\n",
    "            \n",
    "            \n",
    "        # Update epsilon\n",
    "        if END_EPSILON_DECAYING >= episode and episode >= START_EPSILON_DECAYING:\n",
    "            epsilon -= epsilon_decay_value\n",
    "        \n",
    "        # test the model and print test results\n",
    "        if episode % TEST_INTERVAL == 0:\n",
    "            success_run_ = list()\n",
    "            steps_ = list()\n",
    "            for i in range(N_TEST_RUNS):\n",
    "                success_run, steps = test_model(QTable)\n",
    "                success_run_.append(success_run)\n",
    "                steps_.append(steps)\n",
    "                \n",
    "            print('Testing at Episode {}:'.format(episode))\n",
    "            print('\\t Successful Runs: {}/{}'.format(np.sum(success_run_), N_TEST_RUNS) )\n",
    "            print('\\t Average Steps: {}'.format(np.mean(steps_)))\n",
    "\n",
    "    env.close()\n",
    "    \n",
    "    return QTable"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f344f29490a86472adfcb0d4c68c5dfdcf97bca003fdba9df268b07cb4a6c3e0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 ('_penv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
